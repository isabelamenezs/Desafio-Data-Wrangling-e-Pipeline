**Desafio Data Wrangling & Pipeline de Dados**

Este projeto foi desenvolvido como parte do Bootcamp de Business Intelligence (2025) e tem como objetivo criar um pipeline de dados em Python para tratar e carregar um conjunto de dados de vendas online em um banco SQLite.

**Objetivo do Projeto**

A proposta √© automatizar o processo ETL (Extra√ß√£o, Transforma√ß√£o e Carga) de um dataset bruto contendo inconsist√™ncias, aplicando t√©cnicas de data wrangling e boas pr√°ticas de organiza√ß√£o de c√≥digo.

**Funcionalidades Implementadas**
üîπ 1. Extra√ß√£o (extraction.py)

- Leitura do arquivo CSV bruto.

- Visualiza√ß√£o inicial dos dados (head, tipos de colunas, valores nulos).

- Retorno de um DataFrame para as pr√≥ximas etapas.

üîπ 2. Transforma√ß√£o (transform.py)

- Padroniza√ß√£o da coluna de data no formato YYYY-MM-DD.

- Substitui√ß√£o de valores nulos por "N√£o informado".

- Convers√£o de quantidades textuais para inteiros.

- Corre√ß√£o de pre√ßos negativos.

- Cria√ß√£o da coluna valor_total = quantidade * preco_unitario.

üîπ 3. Carga (load.py)

- Cria√ß√£o de um banco de dados SQLite (vendas.db).

- Inser√ß√£o dos dados tratados na tabela tb_vendas.

üîπ 4. Pipeline Principal (pipeline.py)

- Importa as fun√ß√µes dos arquivos anteriores.

- Executa as etapas E ‚Üí T ‚Üí L de forma sequencial.

- Garante o fluxo automatizado de dados do CSV at√© o banco.

**Tecnologias Utilizadas**

Python 3.12+

Pandas

SQLite3 (ou SQLAlchemy)

Jupyter / VS Code / Google Colab (para testes e desenvolvimento)

**Como Executar o Projeto**
1. Clone o reposit√≥rio:
git clone https://github.com/isabelamenezs/Desafio-Data-Wrangling-e-Pipeline
cd <Desafio-Data-Wrangling-e-Pipeline>

2. Instale as depend√™ncias:
pip install pandas sqlalchemy

3. Execute o pipeline:
python pipeline.py

4. Verifique o banco de dados:

Abra o arquivo vendas.db (pode usar o DB Browser for SQLite) e confirme se a tabela tb_vendas foi criada com os dados tratados.
